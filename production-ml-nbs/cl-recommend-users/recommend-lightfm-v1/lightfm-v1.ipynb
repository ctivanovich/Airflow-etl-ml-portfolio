{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "district_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring paths and GCS URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_client = storage.Client(project=\"linkbal-dp\")\n",
    "\n",
    "today = datetime.strftime(datetime.now(tz=pytz.timezone(\"Asia/Tokyo\")), \"%Y%m%d\")\n",
    "\n",
    "bucket = \"cl-personalization.datasets.linkbal.com\"\n",
    "beacon_path = \"gs://\" + bucket + \"/inputs/beacon_events/\"\n",
    "dislikes_file_base = beacon_path + \"recommend-dislikes/{}_daily_recs_dislikes.csv\"\n",
    "\n",
    "### both users and likes data are provided by the collect-recs-data DAG in Airflow\n",
    "prefix = \"inputs/lightfm\"\n",
    "tmp_dir = \"/tmp\"\n",
    "users_file = \"users.csv\"\n",
    "users_path = prefix + \"/\" + users_file\n",
    "likes_file = \"likes.csv\"\n",
    "likes_path = \"gs://\" + bucket + \"/\" + prefix + \"/\" + likes_file\n",
    "\n",
    "rec_output_path = \"gs://\" + bucket + \"/outputs/lightfm_v1_district_{}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = os.cpu_count() - 1 # set this to the number of CPU cores to take advantage of parallel training\n",
    "EPOCHS = 50\n",
    "\n",
    "TARGET_RECS = 50 #also known as k\n",
    "MAX_RECS = 100\n",
    "\n",
    "N_DAYS_DISLIKES_DATA = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khoa-san had this variable below:\n",
    "\n",
    "M_MAX_REC = 400, Maximum number of times a target user gets recommended\n",
    "\n",
    "\n",
    "I'm removing the max rec limitation on individual target users because in some situations, we have to recommend the same user to everybody, we simply don't have enough users to recommend. And if we do want to set a limit, we can do so by making the limit a function of the number of target users vs users available, rather than hard-coding some value that may not apply well to all districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick and dirty fix with bash utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_obj = gcs_client.get_bucket(bucket)\n",
    "bucket_obj.get_blob(f'{users_path}').download_to_filename(f'{tmp_dir}/{users_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $tmp_dir/$users_file | sed 's/\"N,/,/g' | sed 's/\"//g' > $tmp_dir/clean_users.csv\n",
    "! mv $tmp_dir/clean_users.csv $tmp_dir/$users_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cols = [\n",
    "    'user_id',\n",
    "    'gender',\n",
    "    'age',\n",
    "    'self_introduction',\n",
    "    'blood_type',\n",
    "    'brother_and_sister',\n",
    "    'job_id',\n",
    "    'annual_salary_range',\n",
    "    'body_shape',\n",
    "    'education_background',\n",
    "    'hometown_prefecture_id',\n",
    "    'nationality',\n",
    "    'holiday',\n",
    "    'smoking',\n",
    "    'drinking',\n",
    "    'housemate',\n",
    "    'sociality',\n",
    "    'intention_to_marry',\n",
    "    'marital_status',\n",
    "    'absence_or_presence_of_child',\n",
    "    'whether_want_child',\n",
    "    'housework_and_child_rearing',\n",
    "    'meeting_wish_type',\n",
    "    'first_dating_expense_type',\n",
    "    'height',\n",
    "    'personal_color',\n",
    "    'no_lover_history',\n",
    "    'gamble',\n",
    "    'cooking_skill',\n",
    "    'completion_rate',\n",
    "    'district_id',\n",
    "    'created_at'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(\n",
    "    tmp_dir + '/' + users_file,\n",
    "    names = user_cols,\n",
    "    parse_dates = ['created_at'],\n",
    "    dtype = {'user_id': np.int32, 'target_user_id':np.int32}\n",
    ").query('district_id == @district_id').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define discrete variables\n",
    "continuous_vars = ['height', 'age', 'self_introduction']\n",
    "discrete_vars = list(set(user_df.columns) - set(continuous_vars) - set(['user_id','gender']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df, continuous_vars, discrete_vars):\n",
    "    for col in continuous_vars:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    for col in discrete_vars:\n",
    "        df[col].fillna('na', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fillna(user_df, continuous_vars, discrete_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(age, low, high):\n",
    "    if age < low:\n",
    "        return 'lt_' + str(low)\n",
    "    elif age > high:\n",
    "        return 'gt_' + str(high)\n",
    "    else:\n",
    "        return str(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_df['age_cat'] = user_df.age.apply(lambda x: categorize_age(x, 18, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_height(height, low, high):\n",
    "    if height < low:\n",
    "        return 'lt_' + str(low)\n",
    "    elif height > high:\n",
    "        return 'gt_' + str(high)\n",
    "    else:\n",
    "        return str(int(height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['height_cat'] = user_df.apply(\n",
    "    lambda x: categorize_height(x.height, 150, 190) if x.gender == 1 else categorize_height(x.height, 140, 180), \n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_introduction(intro):\n",
    "    if intro == 0:\n",
    "        return 'na'\n",
    "    elif intro > 0 and intro <= 100:\n",
    "        return 'lt_100'\n",
    "    elif intro > 100 and intro <= 200:\n",
    "        return 'gt_100_lt_200'\n",
    "    elif intro > 200 and intro <= 300:\n",
    "        return 'gt_200_lt_300'\n",
    "    elif intro > 300 and intro <= 400:\n",
    "        return 'gt_300_lt_400'\n",
    "    elif intro > 400 and intro <= 500:\n",
    "        return 'gt_400_lt_500'\n",
    "    else:\n",
    "        return 'gt_500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['intro_cat']= user_df.self_introduction.apply(categorize_introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_cols = [\n",
    "    'user_id',\n",
    "    'target_user_id',\n",
    "    'checked',\n",
    "    'matched',\n",
    "    'deleted'\n",
    "]\n",
    "\n",
    "like_df = pd.read_csv(\n",
    "    likes_path,\n",
    "    names = likes_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = like_df.drop_duplicates(subset=['user_id', 'target_user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = like_df[like_df.user_id.isin(user_df.user_id) & like_df.target_user_id.isin(user_df.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df['checked'] = like_df['checked'].astype(bool)\n",
    "like_df['matched'] = like_df['matched'].astype(bool)\n",
    "like_df['deleted'] = like_df['deleted'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dislike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dislikes_df(n_days=14):\n",
    "    dislikes = pd.DataFrame(\n",
    "        [], \n",
    "        columns = [\n",
    "            'user_id',\n",
    "            'target_user_id'\n",
    "        ]\n",
    "    )\n",
    "    for date in np.array([datetime.today() - timedelta(days = i) for i in range(1, n_days + 1)]):\n",
    "        try:\n",
    "            date = date.strftime(\"%Y%m%d\")\n",
    "            print(f\"Obtaining dislikes for {date}\")\n",
    "            dislikes = dislikes.append(\n",
    "                pd.read_csv(\n",
    "                    dislikes_file_base.format(date),\n",
    "                    dtype = {'user_id': np.int32, 'target_user_id':np.int32}\n",
    "                )\n",
    "            )\n",
    "            dislikes.drop_duplicates(inplace = True) \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Could not find dislikes data at {dislikes_file_base.format(date)}. Please examine URI.\")\n",
    "\n",
    "    return dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dislike_df = create_dislikes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dislike_df = pd.read_csv('dislikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reducing dislikes to users and target users in the users dataset\n",
    "\n",
    "dislike_df = dislike_df[(dislike_df.user_id.isin(user_df.user_id.unique())) & (dislike_df.target_user_id.isin(user_df.user_id.unique()))]\n",
    "\n",
    "dislike_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dislike_df.user_id.nunique(), user_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Male - female matches as female - male liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_df = like_df[like_df.matched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = pd.concat(\n",
    "    [\n",
    "        like_df,\n",
    "        match_df.rename(\n",
    "            columns =\n",
    "            {\n",
    "                'user_id': 'target_user_id', \n",
    "                'target_user_id': 'user_id'\n",
    "            }\n",
    "        )\n",
    "    ], \n",
    "    sort=False\n",
    ")\n",
    "\n",
    "del match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = like_df.drop_duplicates(subset=['user_id', 'target_user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_likes_sent = like_df.groupby('user_id').target_user_id.count().\\\n",
    "                            reset_index().\\\n",
    "                            rename(columns={\"target_user_id\": \"user_likes_sent\"})\n",
    "target_likes_received = like_df.groupby('target_user_id').user_id.count().\\\n",
    "                            reset_index().\\\n",
    "                            rename(columns={\"user_id\": \"target_likes_received\"})\n",
    "target_matches = like_df[like_df.matched].groupby('target_user_id').user_id.count().\\\n",
    "                            reset_index().\\\n",
    "                            rename(columns={\"user_id\": \"target_matches\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = like_df.merge(user_likes_sent, on = 'user_id', how = 'left')\n",
    "like_df = like_df.merge(target_likes_received, on='target_user_id', how = 'left')\n",
    "like_df = like_df.merge(target_matches, on='target_user_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df['liked'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = like_df.merge(dislike_df, on=['user_id', 'target_user_id'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del like_df, user_likes_sent, target_likes_received, target_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.matched.fillna(False, inplace=True)\n",
    "merge_df.deleted.fillna(False, inplace=True)\n",
    "merge_df.checked.fillna(False, inplace=True)\n",
    "merge_df.user_likes_sent.fillna(0, inplace=True)\n",
    "merge_df.target_likes_received.fillna(0, inplace=True)\n",
    "merge_df.target_matches.fillna(0, inplace=True)\n",
    "merge_df.liked.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The effect of this is to drop dislike records if a like was eventually sent,\n",
    "### since there should only be one interaction record b/t user and target pair, either like or dislike.\n",
    "### All dislikes duplicated have already been removed, so any duplicates remaining are 1 like and 1 dislike\n",
    "\n",
    "merge_df.drop(\n",
    "    index=merge_df[\n",
    "        (merge_df[['user_id', 'target_user_id']].duplicated(keep=False)) & \n",
    "        (merge_df.liked == 0)].index, \n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.merge(user_df[['user_id', 'gender']], on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df = merge_df[merge_df.gender == 1].copy()\n",
    "female_interaction_df = merge_df[merge_df.gender == 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df.shape[0], female_interaction_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build lightfm dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vars = [\n",
    "       'blood_type', 'brother_and_sister', 'annual_salary_range',\n",
    "       'education_background', 'holiday', 'smoking', 'drinking',\n",
    "       'sociality', 'intention_to_marry', 'marital_status',\n",
    "       'absence_or_presence_of_child', 'whether_want_child',\n",
    "       'housework_and_child_rearing', 'meeting_wish_type',\n",
    "       'first_dating_expense_type', 'body_shape', 'housemate',\n",
    "       'personal_color', 'gamble', 'cooking_skill', 'job_id',\n",
    "       'hometown_prefecture_id', 'age_cat', 'height_cat', 'intro_cat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating indicator variables\n",
    "\n",
    "male_feature_list = []\n",
    "female_feature_list = []\n",
    "\n",
    "# categorical features\n",
    "for var in feature_vars:\n",
    "    male_feature_list += [var + '_' + str(val) for val in user_df[user_df.gender == 1][var].unique()]\n",
    "    female_feature_list += [var + '_' + str(val) for val in user_df[user_df.gender == 2][var].unique()]\n",
    "\n",
    "len(male_feature_list), len(female_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(x):\n",
    "    return (x['user_id'], [var + '_' + str(x[var]) for var in feature_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyperparameters.yaml\", \"r\") as file:\n",
    "    hyperparameters = yaml.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(interactions, weights, item_features, user_features, hyperparameters):\n",
    "    model = LightFM(**hyperparameters)\n",
    "\n",
    "    model.fit(\n",
    "        interactions,\n",
    "        item_features=item_features,\n",
    "        user_features=user_features,\n",
    "        sample_weight=weights,\n",
    "        epochs=EPOCHS,\n",
    "        num_threads=NUM_THREADS,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Males Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"select users who have interactions or who have completed at least half of their profiles.\"\n",
    "\n",
    "m_male_df = user_df[\n",
    "    (user_df.gender == 1) &\n",
    "    (\n",
    "        (user_df.user_id.isin(male_interaction_df.user_id.unique())) | \n",
    "        (user_df.completion_rate > 0.5)\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "m_female_df = user_df[\n",
    "    (user_df.gender == 2) & \n",
    "    (\n",
    "        (user_df.user_id.isin(male_interaction_df.target_user_id.unique())) |\n",
    "        (user_df.completion_rate > 0.5)\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_male_df.shape[0], m_female_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_male_df['features'] = m_male_df.apply(create_features, axis=1)\n",
    "m_female_df['features'] = m_female_df.apply(create_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_m = Dataset()\n",
    "\n",
    "dataset_m.fit(\n",
    "    set(m_male_df['user_id']), \n",
    "    set(m_female_df['user_id']),\n",
    "    user_features=male_feature_list, \n",
    "    item_features=female_feature_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_m = dataset_m.build_user_features(m_male_df['features'])\n",
    "item_features_m = dataset_m.build_item_features(m_female_df['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate interaction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_score(x):\n",
    "    if x['matched']:\n",
    "        return 5\n",
    "    elif x['checked'] or x['deleted'] or not x['liked']:\n",
    "        return 1\n",
    "    elif x['gender'] == 2:\n",
    "        return 4\n",
    "    elif x['gender'] == 1:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['match_score'] = male_interaction_df.apply(match_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['tg_received_penalty'] = 1 / (np.log(male_interaction_df['target_likes_received'] + 1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['sent_penalty'] = 1 / (np.log(male_interaction_df['user_likes_sent'] + 1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['tg_generousness_score'] = np.log(male_interaction_df['target_matches'] + 1)\n",
    "male_interaction_df['tg_generousness_score'] = \\\n",
    "    (male_interaction_df['tg_generousness_score'] - male_interaction_df['tg_generousness_score'].min()) / \\\n",
    "    (male_interaction_df['tg_generousness_score'].max() - male_interaction_df['tg_generousness_score'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_MATCH_SCORE_WEIGHT = 1\n",
    "M_RECEIVED_PENALTY_WEIGHT = 2\n",
    "M_SENT_PENALTY_WEIGHT = 1\n",
    "M_TG_GENEROUSNESS_WEIGHT =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['tg_received_penalty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df['score'] = \\\n",
    "    male_interaction_df['match_score'] * M_MATCH_SCORE_WEIGHT + \\\n",
    "    male_interaction_df['tg_received_penalty'] * M_RECEIVED_PENALTY_WEIGHT + \\\n",
    "    male_interaction_df['sent_penalty'] * M_SENT_PENALTY_WEIGHT + \\\n",
    "    male_interaction_df['tg_generousness_score'] * M_TG_GENEROUSNESS_WEIGHT\n",
    "\n",
    "male_interaction_df['score'] = male_interaction_df.apply(lambda x: 0 if x.liked == 0 else x.score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df = male_interaction_df[\n",
    "    male_interaction_df.user_id.isin(m_male_df.user_id) & \n",
    "    male_interaction_df.target_user_id.isin(m_female_df.user_id)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interaction_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Male Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_interactions, male_weights = dataset_m.build_interactions(\n",
    "    list(zip(male_interaction_df.user_id, male_interaction_df.target_user_id, male_interaction_df.score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_match_df = male_interaction_df[male_interaction_df.matched]\n",
    "male_match_interactions, male_match_weights = dataset_m.build_interactions(\n",
    "    list(zip(male_match_df.user_id, male_match_df.target_user_id))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_m = train_model(male_interactions, male_weights, item_features_m, user_features_m, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Female Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this arbitrary decision to increase the req for male completeness is based on teh assumption\n",
    "### that women will want more info in the profile when considering taking action\n",
    "f_male_df = user_df[\n",
    "    (user_df.gender == 1) &\n",
    "    (\n",
    "        (user_df.user_id.isin(female_interaction_df.user_id.unique())) | \n",
    "        (user_df.completion_rate > 0.7)\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "f_female_df = user_df[\n",
    "    (user_df.gender == 2) &\n",
    "    (\n",
    "        (user_df.user_id.isin(female_interaction_df.user_id.unique())) | \n",
    "        (user_df.completion_rate > 0.5)\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_male_df['features'] = f_male_df.apply(create_features, axis=1)\n",
    "f_female_df['features'] = f_female_df.apply(create_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_f = Dataset()\n",
    "\n",
    "dataset_f.fit(\n",
    "    set(f_female_df['user_id']),\n",
    "    set(f_male_df['user_id']),\n",
    "    user_features=female_feature_list,\n",
    "    item_features=male_feature_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_f = dataset_f.build_user_features(f_female_df['features'])\n",
    "item_features_f = dataset_f.build_item_features(f_male_df['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate interaction score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_score(x):\n",
    "    if x['matched']:\n",
    "        return 5\n",
    "    elif x['checked'] or x['deleted'] or not x['liked']:\n",
    "        return 1\n",
    "    elif x['gender'] == 2:\n",
    "        return 4\n",
    "    elif x['gender'] == 1:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interaction_df['match_score'] = female_interaction_df.apply(match_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interaction_df['tg_received_penalty'] = 1 / (np.log(female_interaction_df['target_likes_received'] + 1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interaction_df['sent_penalty'] = 1 / (np.log(female_interaction_df['user_likes_sent'] + 1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_MATCH_SCORE_WEIGHT = 1\n",
    "F_RECEIVED_PENALTY_WEIGHT = 2\n",
    "F_SENT_PENALTY_WEIGHT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interaction_df['score'] = \\\n",
    "    female_interaction_df['match_score'] * F_MATCH_SCORE_WEIGHT + \\\n",
    "    female_interaction_df['tg_received_penalty'] * F_RECEIVED_PENALTY_WEIGHT + \\\n",
    "    female_interaction_df['sent_penalty'] * F_SENT_PENALTY_WEIGHT\n",
    "\n",
    "female_interaction_df['score'] = female_interaction_df.apply(lambda x: 0 if x.liked == 0 else x.score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interaction_df = female_interaction_df[\n",
    "    female_interaction_df.user_id.isin(f_female_df.user_id) & \n",
    "    female_interaction_df.target_user_id.isin(f_male_df.user_id)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_interactions, female_weights = dataset_f.build_interactions(\n",
    "    list(zip(female_interaction_df.user_id, female_interaction_df.target_user_id, female_interaction_df.score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train female model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_f = train_model(female_interactions, female_weights, item_features_f, user_features_f, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction - function declarations and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map_m, user_feature_map_m, item_id_map_m, item_feature_map_m = dataset_m.mapping()\n",
    "user_id_map_f, user_feature_map_f, item_id_map_f, item_feature_map_f = dataset_f.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cl_conditions(this_user, tg_users):\n",
    "    \"\"\"Filter out target users who meet any of the following conditions: \n",
    "    -> user and targets have different district_id\n",
    "      -> this is handled by subsetting likes on a single district's users data\n",
    "    -> user and targets' user ages are more than 5 years apart\n",
    "    -> target users' accounts are less than 1 day old (new users get special treatment in CL)\n",
    "    -> target users have previously been liked by user (this is done in `filter_target_user` function below)\n",
    "    \"\"\"\n",
    "    one_day_ago = datetime.today() - timedelta(days=1)\n",
    "    age = m_male_df[m_male_df.user_id == this_user].age\n",
    "    filtered_target_users = tg_users[\n",
    "        (tg_users.created_at > one_day_ago) | # find target users with created_at more recent than 1 day ago\n",
    "        ((age - tg_users.age).abs() > 5) # find target users more than 5 years apart from user\n",
    "    ].user_id\n",
    "    \n",
    "    return filtered_target_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_target_user(this_user, tg_users, interactions):\n",
    "    \"\"\"\n",
    "    CL Conditions and additional filters applied: \n",
    "      1. previously liked\n",
    "      2. disliked within 2 weeks\n",
    "    \"\"\"\n",
    "    tg_users_set = set(tg_users.user_id)\n",
    "    liked_tg_users_set = set(\n",
    "        interactions[(interactions.user_id == this_user) & (interactions.liked)].target_user_id\n",
    "    )\n",
    "    disliked_tg_users_set = set(\n",
    "        dislike_df[dislike_df.user_id == this_user].target_user_id\n",
    "    )\n",
    "    cl_conditions = set(apply_cl_conditions(this_user, tg_users))\n",
    "    \n",
    "    return list(tg_users_set - liked_tg_users_set - disliked_tg_users_set - cl_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_and_count_valid_users(tg_list, rec_list, max_recs):\n",
    "    \"\"\"\n",
    "    This function appends recs to a rec list if they do not exceed max_recs, and returns the number of recs obtained\n",
    "    - tg_list - shuffled k recs target_user_ids\n",
    "    - rec_list - contains the final list of recs, begins as an empty list\n",
    "    - tg_user_dict - user_id: rec_count mapping\n",
    "    - max_recs - our stopping point, but for some users there won't be enough people to recommend\n",
    "    \"\"\"\n",
    "\n",
    "    for tg_user_id in tg_list:\n",
    "        if len(rec_list) >= max_recs:  # we've prepared already met our max target\n",
    "            break\n",
    "            \n",
    "        target_user_counts[tg_user_id] = target_user_counts.get(tg_user_id, 0) + 1\n",
    "        \n",
    "        rec_list.append(tg_user_id)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommended_tg(rec_df, target_recs, max_recs):\n",
    "    \"\"\"\n",
    "    - rec_df is a df of user_id, score for a particular user using the model's predict function\n",
    "      sorted from high to low score\n",
    "    - target_recs is equivalent to k\n",
    "    - max_recs is how many we try to provide as padding\n",
    "    \"\"\"\n",
    "    tg_user_id_list = rec_df.user_id.tolist()\n",
    "    top_list = tg_user_id_list[:target_recs]\n",
    "    remain_list = tg_user_id_list[target_recs:]\n",
    "    \n",
    "    # shuffling k users\n",
    "    random.shuffle(top_list)\n",
    "\n",
    "    rec_list = []\n",
    "\n",
    "    # Choose valid user from the top list\n",
    "    append_and_count_valid_users(top_list, rec_list, max_recs)\n",
    "    \n",
    "    # Choose valid user from the remaining list to try to meet max_recs\n",
    "    append_and_count_valid_users(remain_list, rec_list, max_recs)\n",
    "    \n",
    "    return rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_recs_list(model, this_user, target_user_df, interaction_df, item_features, user_features, user_id_map, item_id_map):\n",
    "    target_user_ids_for_rec = filter_target_user(this_user, target_user_df, interaction_df)\n",
    "    if len(target_user_ids_for_rec) == 0:\n",
    "        return []\n",
    "    \n",
    "    ### targets are filtered, and predict is called on each individual user separately, so this is probably as efficient as\n",
    "    ### we are going to get in reducing target user space\n",
    "    predicts = model.predict(\n",
    "        user_id_map[this_user],\n",
    "        [item_id_map[target_id] for target_id in target_user_ids_for_rec],\n",
    "        item_features=item_features,\n",
    "        user_features=user_features\n",
    "    )\n",
    "\n",
    "    predicted_scores = pd.DataFrame({'user_id': target_user_ids_for_rec, 'score': predicts})\n",
    "    predicted_scores.sort_values(by='score', ascending=False, inplace=True)\n",
    "    \n",
    "    sorted_recs_list = get_top_recommended_tg(predicted_scores, TARGET_RECS, MAX_RECS)\n",
    "    \n",
    "    return sorted_recs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_records(model, user_df, target_user_df, interaction_df, item_features, user_features, user_id_map, item_id_map):\n",
    "    rec_records = dict()\n",
    "    for this_user in user_df.user_id:\n",
    "        rec_records[this_user] = []\n",
    "        sorted_recs = get_sorted_recs_list(\n",
    "            model,\n",
    "            this_user, \n",
    "            target_user_df, \n",
    "            interaction_df, \n",
    "            item_features, \n",
    "            user_features, \n",
    "            user_id_map, \n",
    "            item_id_map\n",
    "        )    \n",
    "        for rec in sorted_recs:\n",
    "            rec_records[this_user].append(rec)\n",
    "    return rec_records\n",
    "\n",
    "def generate_pairs(all_recs):\n",
    "    for user, recs in all_recs.items():\n",
    "        for rec in recs:\n",
    "            yield int(user), int(rec)\n",
    "\n",
    "def create_long_df(records):\n",
    "    return pd.DataFrame(\n",
    "            generate_pairs(records), \n",
    "            columns = ['user_id', 'target_user_id']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be declared in this namespace for the below functions to have access outside the scope of application on a per row basis\n",
    "target_user_counts = {}\n",
    "\n",
    "male_rec_records = build_records(\n",
    "    model_m,\n",
    "    m_male_df, \n",
    "    m_female_df, \n",
    "    male_interaction_df, \n",
    "    item_features_m, \n",
    "    user_features_m, \n",
    "    user_id_map_m, \n",
    "    item_id_map_m\n",
    ")\n",
    "male_rec_df = create_long_df(male_rec_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_user_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_rec_df.groupby(\"target_user_id\").user_id.count().plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coverage male: %f%%\"%(male_rec_df.target_user_id.nunique() / m_female_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"But, the top 10 most recommended users have been recommended as follows:\")\n",
    "    \n",
    "sorted(target_user_counts.items(), key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user_counts = {}\n",
    "\n",
    "female_rec_records = build_records(\n",
    "    model_f,\n",
    "    f_female_df, \n",
    "    f_male_df, \n",
    "    female_interaction_df, \n",
    "    item_features_f, \n",
    "    user_features_f, \n",
    "    user_id_map_f, \n",
    "    item_id_map_f\n",
    ")\n",
    "\n",
    "female_rec_df = create_long_df(female_rec_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_rec_df.groupby(\"target_user_id\").user_id.count().plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coverage female: %f%%\"%(female_rec_df.target_user_id.nunique() / f_male_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"But, the top 10 most recommended users have been recommended as follows:\")\n",
    "sorted(target_user_counts.items(), key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and deliver output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_recs_df = pd.concat(\n",
    "    [\n",
    "        male_rec_df,\n",
    "        female_rec_df\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_recs_df.to_csv(rec_output_path.format(district_id), index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up file just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm $tmp_dir/$users_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
