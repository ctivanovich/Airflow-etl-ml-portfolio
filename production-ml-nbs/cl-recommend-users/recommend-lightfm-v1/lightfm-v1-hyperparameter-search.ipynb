{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyperparameters.yaml\", \"r\") as file:\n",
    "    hyperparameters = yaml.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = os.cpu_count() # set this to the number of CPU cores to take advantage of parallel training\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_hyperparameters():\n",
    "    \"\"\"\n",
    "    Yield possible hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            \"no_components\": np.random.randint(50, 150),\n",
    "            \"learning_schedule\": np.random.choice([\"adagrad\", \"adadelta\"]),\n",
    "            \"loss\": np.random.choice([\"warp\", \"bpr\"]),\n",
    "            \"learning_rate\": np.random.exponential(0.05),\n",
    "            \"max_sampled\": np.random.randint(5, 15),\n",
    "            \"num_epochs\": np.random.randint(50, 150),\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search(i_train, i_test, w_train, w_test, dwriter, num_samples=10):\n",
    "    \"\"\"\n",
    "    Sample random hyperparameters, fit a LightFM model, and evaluate it\n",
    "    on the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Training data.\n",
    "    test: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Test data.\n",
    "    num_samples: int, optional\n",
    "        Number of hyperparameter choices to evaluate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    generator of (auc_score, hyperparameter dict, fitted model)\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(num_samples):\n",
    "        hyperparams = sample_hyperparameters().__next__()\n",
    "        print(\"---Training with hyperparameters---\")\n",
    "        pprint(hyperparams)\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "\n",
    "        model = LightFM(**hyperparams)\n",
    "        start = time.time()\n",
    "        model.fit(\n",
    "            i_train,\n",
    "            item_features=item_features_m,\n",
    "            user_features=user_features_m,\n",
    "            sample_weight=w_train,\n",
    "            verbose=False,\n",
    "            epochs=num_epochs, \n",
    "            num_threads=NUM_THREADS\n",
    "        )\n",
    "        train_time = int(time.time() - start)\n",
    "        score = precision_at_k(\n",
    "            model, \n",
    "            test_interactions=m_i_test,\n",
    "            train_interactions=m_i_train, \n",
    "            user_features = user_features_m,\n",
    "            item_features = item_features_m,\n",
    "            k = 50,\n",
    "            num_threads=NUM_THREADS,\n",
    "            check_intersections=False\n",
    "            ).mean()\n",
    "\n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "        hyperparams[\"train_time\"] = train_time\n",
    "        hyperparams[\"score\"] = score\n",
    "        dwriter.writerow(hyperparams)\n",
    "        yield (score, hyperparams, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyperparameters-warp-100.csv\", \"w\") as outcsv, open(\"hyperparameters.yaml\", \"r\") as hypfile:\n",
    "    dwriter = csv.DictWriter(\n",
    "        outcsv, \n",
    "        fieldnames=[\n",
    "            \"num_epochs\",\n",
    "            \"train_time\",\n",
    "            \"mar@k\",\n",
    "            \"map@k\",\n",
    "            \"auc\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dwriter.writeheader()\n",
    "\n",
    "    hyperparams = yaml.load(hypfile)\n",
    "    \n",
    "    for num_epochs in range(50, 151, 10):\n",
    "        csv_output = {}\n",
    "        \n",
    "        male_interactions, male_weights = dataset_m.build_interactions(\n",
    "            list(zip(male_interaction_df.user_id, male_interaction_df.target_user_id, male_interaction_df.score))\n",
    "        )\n",
    "\n",
    "        m_i_train, m_i_test, m_w_train, m_w_test = train_test_split(male_interactions, male_weights, test_size = 0.33)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        model = LightFM(**hyperparams)\n",
    "        model.fit(\n",
    "            m_i_train,\n",
    "            item_features=item_features_m,\n",
    "            user_features=user_features_m,\n",
    "            sample_weight=m_w_train.tocoo(),\n",
    "            verbose=False,\n",
    "            epochs=num_epochs, \n",
    "            num_threads=NUM_THREADS\n",
    "        )\n",
    "\n",
    "        train_time = int(time.time() - start)\n",
    "\n",
    "        mapk = precision_at_k(\n",
    "            model, \n",
    "            test_interactions=m_i_test,\n",
    "            train_interactions=m_i_train, \n",
    "            user_features = user_features_m,\n",
    "            item_features = item_features_m,\n",
    "            k = 50,\n",
    "            num_threads=NUM_THREADS,\n",
    "            check_intersections=False\n",
    "        ).mean()\n",
    "        mark = recall_at_k(\n",
    "            model, \n",
    "            test_interactions=m_i_test,\n",
    "            train_interactions=m_i_train, \n",
    "            user_features = user_features_m,\n",
    "            item_features = item_features_m,\n",
    "            k = 50,\n",
    "            num_threads=NUM_THREADS,\n",
    "            check_intersections=False\n",
    "        ).mean()\n",
    "        auc = auc_score(\n",
    "            model,\n",
    "            test_interactions=m_i_test,\n",
    "            train_interactions=m_i_train,\n",
    "            user_features=user_features_m,\n",
    "            item_features=item_features_m,\n",
    "            preserve_rows=False,\n",
    "            num_threads=NUM_THREADS,\n",
    "            check_intersections=False\n",
    "        ).mean()\n",
    "\n",
    "        csv_output[\"num_epochs\"] = num_epochs\n",
    "        csv_output[\"train_time\"] = train_time\n",
    "        csv_output[\"mar@k\"] = mark\n",
    "        csv_output[\"map@k\"] = mapk\n",
    "        csv_output[\"auc\"] = auc\n",
    "\n",
    "        dwriter.writerow(csv_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}